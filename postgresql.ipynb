{
 "metadata": {
  "name": "",
  "signature": "sha256:51f97d684e48e2ab1c5e927033b918f305fc579a609e1c437b30840a5376bc7f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Setup"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run these cells before any others in the notebook.\n",
      "\n",
      "First, load the [ipython_sql](https://pypi.python.org/pypi/ipython-sql) magic.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%load_ext sql"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Then create a connection to your database.  Use [SQLAlchemy connection format](http://docs.sqlalchemy.org/en/latest/core/engines.html#database-urls):\n",
      "\n",
      "    postgresql://username:password@host/dbname"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To customize the connection string for your own database while leaving notebook generic, fill in environment variables `$PG_USERNAME`, `$PG_PASSWORD`, `$PG_DATABASE`, and (optionally) `$PG_HOST`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "pg_host = os.getenv('PG_HOST') or 'localhost'\n",
      "pg_database = os.getenv('PG_DATABASE') or 'shakes'\n",
      "pg_username = os.getenv('PG_USERNAME') or 'will'\n",
      "pg_password = os.getenv('PG_PASSWORD') or 'longliveliz'\n",
      "connection_string = \"postgresql://%s:%s@%s/%s\" % (pg_username, pg_password, pg_host, pg_database)\n",
      "print(\"Connection is to \" + connection_string)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sample database comes from [opensourceshakespeare](https://github.com/catherinedevlin/opensourceshakespeare)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%sql $connection_string"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to run the queries that check operating system statistics, you will also need to install [Fabric](fabfile.org)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import fabric\n",
      "import fabric.api"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Status"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Queries in progress"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Postgresql < 9.2?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%sql select * from pg_stat_activity where current_query not like '%pg_stat_activity%'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Postgresql >= 9.2 only?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%sql select * from pg_stat_activity where query not like '%pg_stat_activity%'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Locks"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql \n",
      "select t.relname,l.locktype,page,virtualtransaction,pid,mode,granted from pg_locks l, pg_stat_all_tables t where l.relation=t.relid order by relation asc;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Disk use"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "OS-level total disk use"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "On your local machine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fabric.api.local('df -h') # broken"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The output of this never gets captured... it's actually printed to screen in the terminal that's running `ipython notebook`.  If anybody can explain / fix this behavior, I'll be grateful!"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "On a remote machine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with fabric.api.settings(host_string='username@host'):\n",
      "    print fabric.api.run('df -h')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Total database usage"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Credit: [Postgresql Wiki](http://wiki.postgresql.org/wiki/Disk_Usage)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql \n",
      "SELECT d.datname AS Name,  pg_catalog.pg_get_userbyid(d.datdba) AS Owner,\n",
      "    CASE WHEN pg_catalog.has_database_privilege(d.datname, 'CONNECT')\n",
      "        THEN pg_catalog.pg_size_pretty(pg_catalog.pg_database_size(d.datname))\n",
      "        ELSE 'No Access'\n",
      "    END AS Size\n",
      "FROM pg_catalog.pg_database d\n",
      "    ORDER BY\n",
      "    CASE WHEN pg_catalog.has_database_privilege(d.datname, 'CONNECT')\n",
      "        THEN pg_catalog.pg_database_size(d.datname)\n",
      "        ELSE NULL\n",
      "    END DESC -- nulls first\n",
      "    LIMIT 20\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Largest relations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Credit](http://wiki.postgresql.org/wiki/Disk_Usage)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql\n",
      "SELECT nspname || '.' || relname AS \"relation\",\n",
      "    pg_size_pretty(pg_relation_size(C.oid)) AS \"size\"\n",
      "  FROM pg_class C\n",
      "  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)\n",
      "  WHERE nspname NOT IN ('pg_catalog', 'information_schema')\n",
      "  ORDER BY pg_relation_size(C.oid) DESC\n",
      "  LIMIT 20;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Total size of biggest tables (including their indexes)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Credit](http://wiki.postgresql.org/wiki/Disk_Usage)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql\n",
      "  SELECT nspname || '.' || relname AS \"relation\",\n",
      "    pg_size_pretty(pg_total_relation_size(C.oid)) AS \"total_size\"\n",
      "  FROM pg_class C\n",
      "  LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)\n",
      "  WHERE nspname NOT IN ('pg_catalog', 'information_schema')\n",
      "    AND C.relkind <> 'i'\n",
      "    AND nspname !~ '^pg_toast'\n",
      "  ORDER BY pg_total_relation_size(C.oid) DESC\n",
      "  LIMIT 20;\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Bloat"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Credit](http://www.databasesoup.com/2014/10/new-table-bloat-query.html)"
     ]
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Index Bloat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql\n",
      "WITH btree_index_atts AS (\n",
      "    SELECT nspname, relname, reltuples, relpages, indrelid, relam,\n",
      "        regexp_split_to_table(indkey::text, ' ')::smallint AS attnum,\n",
      "        indexrelid as index_oid\n",
      "    FROM pg_index\n",
      "    JOIN pg_class ON pg_class.oid=pg_index.indexrelid\n",
      "    JOIN pg_namespace ON pg_namespace.oid = pg_class.relnamespace\n",
      "    JOIN pg_am ON pg_class.relam = pg_am.oid\n",
      "    WHERE pg_am.amname = 'btree'\n",
      "    ),\n",
      "index_item_sizes AS (\n",
      "    SELECT\n",
      "    i.nspname, i.relname, i.reltuples, i.relpages, i.relam,\n",
      "    s.starelid, a.attrelid AS table_oid, index_oid,\n",
      "    current_setting('block_size')::numeric AS bs,\n",
      "    8 AS maxalign,\n",
      "    24 AS pagehdr,\n",
      "    /* per tuple header: add index_attribute_bm if some cols are null-able */\n",
      "    CASE WHEN max(coalesce(s.stanullfrac,0)) = 0\n",
      "        THEN 2\n",
      "        ELSE 6\n",
      "    END AS index_tuple_hdr,\n",
      "    /* data len: we remove null values save space using it fractionnal part from stats */\n",
      "    sum( (1-coalesce(s.stanullfrac, 0)) * coalesce(s.stawidth, 2048) ) AS nulldatawidth\n",
      "    FROM pg_attribute AS a\n",
      "    JOIN pg_statistic AS s ON s.starelid=a.attrelid AND s.staattnum = a.attnum\n",
      "    JOIN btree_index_atts AS i ON i.indrelid = a.attrelid AND a.attnum = i.attnum\n",
      "    WHERE a.attnum > 0\n",
      "    GROUP BY 1, 2, 3, 4, 5, 6, 7, 8, 9\n",
      "),\n",
      "index_aligned AS (\n",
      "    SELECT maxalign, bs, nspname, relname AS index_name, reltuples,\n",
      "        relpages, relam, table_oid, index_oid,\n",
      "      ( 2 +\n",
      "          maxalign - CASE /* Add padding to the index tuple header to align on MAXALIGN */\n",
      "            WHEN index_tuple_hdr%maxalign = 0 THEN maxalign\n",
      "            ELSE index_tuple_hdr%maxalign\n",
      "          END\n",
      "        + nulldatawidth + maxalign - CASE /* Add padding to the data to align on MAXALIGN */\n",
      "            WHEN nulldatawidth::integer%maxalign = 0 THEN maxalign\n",
      "            ELSE nulldatawidth::integer%maxalign\n",
      "          END\n",
      "      )::numeric AS nulldatahdrwidth, pagehdr\n",
      "    FROM index_item_sizes AS s1\n",
      "),\n",
      "otta_calc AS (\n",
      "  SELECT bs, nspname, table_oid, index_oid, index_name, relpages, coalesce(\n",
      "    ceil((reltuples*(4+nulldatahdrwidth))/(bs-pagehdr::float)) +\n",
      "      CASE WHEN am.amname IN ('hash','btree') THEN 1 ELSE 0 END , 0 -- btree and hash have a metadata reserved block\n",
      "    ) AS otta\n",
      "  FROM index_aligned AS s2\n",
      "    LEFT JOIN pg_am am ON s2.relam = am.oid\n",
      "),\n",
      "raw_bloat AS (\n",
      "    SELECT current_database() as dbname, nspname, c.relname AS table_name, index_name,\n",
      "        bs*(sub.relpages)::bigint AS totalbytes, otta as expected,\n",
      "        CASE\n",
      "            WHEN sub.relpages <= otta THEN 0\n",
      "            ELSE bs*(sub.relpages-otta)::bigint END\n",
      "            AS wastedbytes,\n",
      "        CASE\n",
      "            WHEN sub.relpages <= otta\n",
      "            THEN 0 ELSE bs*(sub.relpages-otta)::bigint * 100 / (bs*(sub.relpages)::bigint) END\n",
      "            AS realbloat,\n",
      "        pg_relation_size(sub.table_oid) as table_bytes,\n",
      "        stat.idx_scan as index_scans\n",
      "    FROM otta_calc AS sub\n",
      "    JOIN pg_class AS c ON c.oid=sub.table_oid\n",
      "    JOIN pg_stat_user_indexes AS stat ON sub.index_oid = stat.indexrelid\n",
      "),\n",
      "format_bloat AS (\n",
      "SELECT dbname as database_name, nspname as schema_name, table_name, index_name,\n",
      "        round(realbloat) as bloat_pct, round(wastedbytes/(1024^2)::NUMERIC) as bloat_mb,\n",
      "        round(totalbytes/(1024^2)::NUMERIC,3) as index_mb,\n",
      "        round(table_bytes/(1024^2)::NUMERIC,3) as table_mb,\n",
      "        index_scans\n",
      "FROM raw_bloat\n",
      ")\n",
      "-- final query outputting the bloated indexes\n",
      "-- change the where and order by to change\n",
      "-- what shows up as bloated\n",
      "SELECT *\n",
      "FROM format_bloat\n",
      "WHERE ( bloat_pct > 50 and bloat_mb > 10 )\n",
      "ORDER BY bloat_mb DESC;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Table bloat"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql\n",
      "-- new table bloat query\n",
      "-- still needs work; is often off by +/- 20%\n",
      "WITH constants AS (\n",
      "    -- define some constants for sizes of things\n",
      "    -- for reference down the query and easy maintenance\n",
      "    SELECT current_setting('block_size')::numeric AS bs, 23 AS hdr, 8 AS ma\n",
      "),\n",
      "no_stats AS (\n",
      "    -- screen out table who have attributes\n",
      "    -- which dont have stats, such as JSON\n",
      "    SELECT table_schema, table_name\n",
      "    FROM information_schema.columns\n",
      "        LEFT OUTER JOIN pg_stats\n",
      "        ON table_schema = schemaname\n",
      "            AND table_name = tablename\n",
      "            AND column_name = attname\n",
      "    WHERE attname IS NULL\n",
      "        AND table_schema NOT IN ('pg_catalog', 'information_schema')\n",
      "    GROUP BY table_schema, table_name\n",
      "),\n",
      "null_headers AS (\n",
      "    -- calculate null header sizes\n",
      "    -- omitting tables which dont have complete stats\n",
      "    -- and attributes which aren't visible\n",
      "    SELECT\n",
      "        hdr+1+(sum(case when null_frac <> 0 THEN 1 else 0 END)/8) as nullhdr,\n",
      "        SUM((1-null_frac)*avg_width) as datawidth,\n",
      "        MAX(null_frac) as maxfracsum,\n",
      "        schemaname,\n",
      "        tablename,\n",
      "        hdr, ma, bs\n",
      "    FROM pg_stats CROSS JOIN constants\n",
      "        LEFT OUTER JOIN no_stats\n",
      "            ON schemaname = no_stats.table_schema\n",
      "            AND tablename = no_stats.table_name\n",
      "    WHERE schemaname NOT IN ('pg_catalog', 'information_schema')\n",
      "        AND no_stats.table_name IS NULL\n",
      "        AND EXISTS ( SELECT 1\n",
      "            FROM information_schema.columns\n",
      "                WHERE schemaname = columns.table_schema\n",
      "                    AND tablename = columns.table_name )\n",
      "    GROUP BY schemaname, tablename, hdr, ma, bs\n",
      "),\n",
      "data_headers AS (\n",
      "    -- estimate header and row size\n",
      "    SELECT\n",
      "        ma, bs, hdr, schemaname, tablename,\n",
      "        (datawidth+(hdr+ma-(case when hdr%ma=0 THEN ma ELSE hdr%ma END)))::numeric AS datahdr,\n",
      "        (maxfracsum*(nullhdr+ma-(case when nullhdr%ma=0 THEN ma ELSE nullhdr%ma END))) AS nullhdr2\n",
      "    FROM null_headers\n",
      "),\n",
      "table_estimates AS (\n",
      "    -- make estimates of how large the table should be\n",
      "    -- based on row and page size\n",
      "    SELECT schemaname, tablename, bs,\n",
      "        reltuples, relpages * bs as table_bytes,\n",
      "    CEIL((reltuples*\n",
      "            (datahdr + nullhdr2 + 4 + ma -\n",
      "                (CASE WHEN datahdr%ma=0\n",
      "                    THEN ma ELSE datahdr%ma END)\n",
      "                )/(bs-20))) * bs AS expected_bytes\n",
      "    FROM data_headers\n",
      "        JOIN pg_class ON tablename = relname\n",
      "        JOIN pg_namespace ON relnamespace = pg_namespace.oid\n",
      "            AND schemaname = nspname\n",
      "    WHERE pg_class.relkind = 'r'\n",
      "),\n",
      "table_estimates_plus AS (\n",
      "-- add some extra metadata to the table data\n",
      "-- and calculations to be reused\n",
      "-- including whether we cant estimate it\n",
      "-- or whether we think it might be compressed\n",
      "    SELECT current_database() as databasename,\n",
      "            schemaname, tablename, reltuples as est_rows,\n",
      "            CASE WHEN expected_bytes > 0 AND table_bytes > 0 THEN\n",
      "                TRUE ELSE FALSE END as can_estimate,\n",
      "            CASE WHEN expected_bytes > table_bytes THEN\n",
      "                TRUE ELSE FALSE END as is_compressed,\n",
      "            CASE WHEN table_bytes > 0\n",
      "                THEN table_bytes::NUMERIC\n",
      "                ELSE NULL::NUMERIC END\n",
      "                AS table_bytes,\n",
      "            CASE WHEN expected_bytes > 0 \n",
      "                THEN expected_bytes::NUMERIC\n",
      "                ELSE NULL::NUMERIC END\n",
      "                    AS expected_bytes,\n",
      "            CASE WHEN expected_bytes > 0 AND table_bytes > 0\n",
      "                AND expected_bytes <= table_bytes\n",
      "                THEN (table_bytes - expected_bytes)::NUMERIC\n",
      "                ELSE 0::NUMERIC END AS bloat_bytes\n",
      "    FROM table_estimates\n",
      "),\n",
      "bloat_data AS (\n",
      "    -- do final math calculations and formatting\n",
      "    select current_database() as databasename,\n",
      "        schemaname, tablename, can_estimate, is_compressed,\n",
      "        table_bytes, round(table_bytes/(1024^2)::NUMERIC,3) as table_mb,\n",
      "        expected_bytes, round(expected_bytes/(1024^2)::NUMERIC,3) as expected_mb,\n",
      "        round(bloat_bytes*100/table_bytes) as pct_bloat,\n",
      "        round(bloat_bytes/(1024::NUMERIC^2),2) as mb_bloat,\n",
      "        table_bytes, expected_bytes\n",
      "    FROM table_estimates_plus\n",
      ")\n",
      "-- filter output for bloated tables\n",
      "SELECT databasename, schemaname, tablename,\n",
      "    --can_estimate, is_compressed,\n",
      "    pct_bloat, mb_bloat,\n",
      "    table_mb\n",
      "FROM bloat_data\n",
      "-- this where clause defines which tables actually appear\n",
      "-- in the bloat chart\n",
      "-- example below filters for tables which are either 50%\n",
      "-- bloated and more than 20mb in size, or more than 25%\n",
      "-- bloated and more than 4GB in size\n",
      "WHERE ( pct_bloat >= 50 AND mb_bloat >= 10 )\n",
      "    OR ( pct_bloat >= 25 AND mb_bloat >= 1000 )\n",
      "ORDER BY pct_bloat DESC;"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Schema"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Indexes"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Credit](http://stackoverflow.com/questions/2204058/show-which-columns-an-index-is-on-in-postgresql/2213199#2213199)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%sql select\n",
      "    n.nspname || '.' || t.relname as table_name,\n",
      "    i.relname as index_name,\n",
      "    array_to_string(array_agg(a.attname), ', ') as column_names,\n",
      "    pg_size_pretty(pg_relation_size(i.oid)) AS \"size\"\n",
      "from\n",
      "    pg_class t,\n",
      "    pg_class i,\n",
      "    pg_index ix,\n",
      "    pg_attribute a,\n",
      "    pg_namespace n\n",
      "where\n",
      "    t.oid = ix.indrelid\n",
      "    and i.oid = ix.indexrelid\n",
      "    and t.relnamespace = n.oid\n",
      "    and a.attrelid = t.oid\n",
      "    and a.attnum = ANY(ix.indkey)\n",
      "    and t.relkind = 'r'\n",
      "    and t.relname like 'licensing'\n",
      "group by\n",
      "    n.nspname,\n",
      "    t.relname,\n",
      "    i.relname,\n",
      "    i.oid\n",
      "order by\n",
      "    t.relname,\n",
      "    i.relname;    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 5,
     "metadata": {},
     "source": [
      "Foreign keys"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Credit](http://solaimurugan.blogspot.com/2010/10/list-out-all-forien-key-constraints.html)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}